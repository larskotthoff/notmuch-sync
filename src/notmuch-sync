#!/usr/bin/env python

import argparse
import sys
import os
import struct
import subprocess
import socket
from select import select
import json
import shlex
import shutil
import hashlib
import asyncio
from pathlib import Path

import notmuch2

transfer = {"read": 0, "write": 0}

def write(data, stream):
    stream.write(struct.pack("!I", len(data)))
    transfer["write"] += 4
    stream.write(data)
    transfer["write"] += len(data)
    stream.flush()


def read(stream):
    size_data = stream.read(4)
    transfer["read"] += 4
    size = struct.unpack("!I", size_data)[0]
    transfer["read"] += size
    return stream.read(size)


def get_changes(db, revision, prefix, fname):
    """Get changes that happened since the last sync, or everything in the DB if no previous sync."""
    rev_prev = -1
    try:
        with open(fname, 'r', encoding="utf-8") as f:
            tmp = f.read().strip('\n\r').split(' ')
            uuid = revision.uuid.decode()
            try:
                if tmp[1] != uuid:
                    sys.exit(f"Last sync with UUID {tmp[1]}, but notmuch DB has UUID {uuid}, aborting...")
                rev_prev = int(tmp[0])
                if rev_prev > revision.rev:
                    sys.exit(f"Last sync revision {rev_prev} larger than current DB revision {revision.rev}, aborting...")
            except Exception:
                sys.exit(f"Sync state file '{fname}' corrupted, delete to sync from scratch.")
    except FileNotFoundError:
        # no previous sync or sync file broken, leave rev_prev at 0 as this will sync entire DB
        pass

    return {msg.messageid: {"tags": list(msg.tags), "files": [
        {"name": str(f).removeprefix(prefix),
         "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()} for f in msg.filenames()
        ]} for msg in db.messages(f"lastmod:{rev_prev + 1}..")}


def sync_tags(args, db, changes_mine, changes_theirs):
    changes = 0
    for id in changes_theirs:
        tags = changes_theirs[id]["tags"]
        if id in changes_mine:
            tags = set(tags) | set(changes_mine[id]["tags"])
        tags = set(tags)
        try:
            msg = db.find(id)
            if tags != set(msg.tags):
                args.verbose > 0 and print(f"Setting tags {sorted(list(tags))} for {id}.")
                with msg.frozen():
                    changes += 1
                    msg.tags.clear()
                    for tag in sorted(list(tags)):
                        msg.tags.add(tag)
                    msg.tags.to_maildir_flags()
        except LookupError:
            # we don't have this message on our side, it will be added later
            # when syncing files
            pass

    return changes


def initial_sync(args, from_stream, to_stream):
    # only do tag sync initially to avoid locking db during lengthy file transfers
    with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
        prefix = os.path.join(str(dbw.default_path()), '')
        revision = dbw.revision()
        # using a hash here b/c of Python's scoping rules -- need to set this in
        # the async function
        uuids = {}
        uuids["mine"] = revision.uuid.decode()

        async def send_uuid():
            args.verbose > 0 and print("Sending UUID...")
            to_stream.write(uuids["mine"].encode("utf-8"))
            transfer["write"] += 36
            to_stream.flush()

        async def recv_uuid():
            args.verbose > 0 and print("Receiving UUID...")
            uuids["theirs"] = from_stream.read(36).decode("utf-8")
            transfer["read"] += 36

        async def sync_uuids():
            await asyncio.gather(send_uuid(), recv_uuid())

        asyncio.run(sync_uuids())
        args.verbose > 0 and print("UUIDs synced.")
        fname = os.path.join(prefix, ".notmuch", f"notmuch-sync-{uuids["theirs"]}")

        changes = {}
        args.verbose > 0 and print("Computing local changes...")
        changes["mine"] = get_changes(dbw, revision, prefix, fname)

        async def send():
            args.verbose > 0 and print("Sending local changes...")
            write(json.dumps(changes["mine"]).encode("utf-8"), to_stream)

        async def recv():
            args.verbose > 0 and print("Receiving remote changes...")
            changes["theirs"] = json.loads(read(from_stream).decode("utf-8"))

        async def sync():
            await asyncio.gather(send(), recv())

        asyncio.run(sync())
        args.verbose > 0 and print("Changes synced.")
        tchanges = sync_tags(args, dbw, changes["mine"], changes["theirs"])
        args.verbose > 0 and print("Tags synced.")

        # record last sync here -- this means that later changes (adding files,
        # adding messages, deleting) will show up during the next sync, but we
        # check whether there are any actual changes, so they shouldn't result
        # in a cascading torrent
        # if we don't record the last sync here, we might miss external changes
        # during the next stages, as the DB is no longer locked
        with open(fname, 'w', encoding="utf-8") as f:
            revision = dbw.revision()
            args.verbose > 0 and print(f"Writing last sync revision {revision.rev}.")
            f.write(f"{revision.rev} {revision.uuid.decode()}")

    return (prefix, changes["mine"], changes["theirs"], tchanges)


def get_missing_files(args, changes_mine, changes_theirs, prefix):
    ret = {}
    mcchanges = 0
    dchanges = 0
    with notmuch2.Database() as db:
        for id in changes_theirs:
            try:
                msg = db.find(id)
                fnames_theirs = [ f["name"] for f in changes_theirs[id]["files"] ]
                fnames_mine = [ str(f).removeprefix(prefix) for f in msg.filenames() ]
                missing_mine = [ f for f in fnames_theirs if f not in fnames_mine ]
                if len(missing_mine) > 0:
                    hashes_mine = [{"name": str(f).removeprefix(prefix),
                                    "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()}
                                    for f in msg.filenames()]
                    for f in changes_theirs[id]["files"]:
                        if f["name"] in missing_mine:
                            # check if it has been moved/copied
                            matches = [ x for x in hashes_mine if f["sha"] == x["sha"] ]
                            if len(matches) > 0:
                                mcchanges += 1
                                src = os.path.join(prefix, matches[0]["name"])
                                dst = os.path.join(prefix, f["name"])
                                # if there's a local change for this ID, copy
                                # this is to prevent inconsistencies when
                                # changes happen on both sides
                                if matches[0] in changes_theirs[id]["files"] or id in changes_mine:
                                    args.verbose > 0 and print(f"Copying {src} to {dst}.")
                                    shutil.copy(src, dst)
                                else:
                                    args.verbose > 0 and print(f"Moving {src} to {dst}.")
                                    shutil.move(src, dst)
                                with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                                    dbw.add(dst)
                                    # see above comment for local changes check
                                    if matches[0] not in changes_theirs[id]["files"] and id not in changes_mine:
                                        args.verbose > 0 and print(f"Removing {src} from DB.")
                                        dbw.remove(src)
                                missing_mine.remove(f["name"])
                # check which ones are still missing
                if len(missing_mine) > 0:
                    ret[id] = {"files": [f for f in changes_theirs[id]["files"] if f["name"] in missing_mine]}
                
                # delete any files that are not there remotely after copy/move
                if args.delete and id not in changes_mine:
                    msg = db.find(id)
                    fnames_mine = [ str(f).removeprefix(prefix) for f in msg.filenames() ]
                    to_delete = [ f for f in fnames_mine if f not in fnames_theirs ]
                    with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                        for f in to_delete:
                            fname = os.path.join(prefix, f)
                            dchanges += 1
                            args.verbose > 0 and print(f"Removing {fname} from DB and deleting file.")
                            dbw.remove(fname)
                            Path(fname).unlink()
            except LookupError:
                # don't have this message; all files missing
                ret[id] = changes_theirs[id]
    return (ret, mcchanges, dchanges)


def send_file(fname, stream):
    with open(fname, "rb") as f:
        write(f.read(), stream)


def recv_file(fname, stream, sha):
    content = read(stream)
    sha_mine = hashlib.new("sha256", content).hexdigest()
    if sha_mine != sha:
        raise ValueError(f"Checksum of received file '{fname}' ({sha_mine}) does not match expected ({sha})!")
    Path(fname).parent.mkdir(parents=True, exist_ok=True)
    with open(fname, "wb") as f:
        f.write(content)


def sync_files(args, prefix, missing, from_stream, to_stream):
    files = {}
    files["mine"] = [ f | {"id": id} for id in missing for f in missing[id]["files"] ]
    changes = {"files": len(files["mine"]), "messages": 0}

    async def send_fnames():
        args.verbose > 0 and print("Sending file names missing on local...")
        to_stream.write(struct.pack("!I", len(files["mine"])))
        transfer["write"] += 4
        to_stream.flush()
        for f in files["mine"]:
            write(f["name"].encode("utf-8"), to_stream)

    async def recv_fnames():
        args.verbose > 0 and print("Receving file names missing on remote...")
        size_data = from_stream.read(4)
        transfer["read"] += 4
        nfiles = struct.unpack("!I", size_data)[0]
        files["theirs"] = [ read(from_stream).decode("utf-8") for _ in range(nfiles) ]

    async def sync_fnames():
        await asyncio.gather(send_fnames(), recv_fnames())

    asyncio.run(sync_fnames())
    args.verbose > 0 and print("Missing file names synced.")

    async def send_files():
        for idx, fname in enumerate(files["theirs"]):
            args.verbose > 0 and print(f"{idx + 1}/{len(files["theirs"])} Sending {fname}...")
            send_file(os.path.join(prefix, fname), to_stream)
    
    async def recv_files():
        for idx, f in enumerate(files["mine"]):
            args.verbose > 0 and print(f"{idx + 1}/{len(files["mine"])} Receiving {f["name"]}...")
            dst = os.path.join(prefix, f["name"])
            recv_file(dst, from_stream, f["sha"])
            with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                args.verbose > 0 and print(f"Adding {dst} to DB.")
                msg, dup = dbw.add(dst)
                if not dup:
                    changes["messages"] += 1
                    with msg.frozen():
                        args.verbose > 0 and print(f"Setting tags {sorted(missing[f["id"]]["tags"])} for {msg.messageid}.")
                        msg.tags.clear()
                        for tag in missing[f["id"]]["tags"]:
                            msg.tags.add(tag)

    async def sync():
        await asyncio.gather(send_files(), recv_files())

    asyncio.run(sync())
    args.verbose > 0 and print("Missing files synced.")

    return changes


# Separate methods for local and remote to avoid sending all IDs both ways --
# have local figure out what needs to be deleted on both sides
def sync_deletes_local(args, from_stream, to_stream):
    ids = {}
    dels = {'a': 0}

    async def get_ids():
        with notmuch2.Database() as db:
            args.verbose > 0 and print("Getting all message IDs from DB...")
            msgs = db.messages('*')
            ids["mine"] = [ msg.messageid for msg in msgs ]

    async def recv_ids():
        args.verbose > 0 and print("Receiving all message IDs from remote...")
        size_data = from_stream.read(4)
        transfer["read"] += 4
        nids = struct.unpack("!I", size_data)[0]
        ids["theirs"] = [ read(from_stream).decode("utf-8") for _ in range(nids) ]

    async def sync_ids():
        await asyncio.gather(get_ids(), recv_ids())

    asyncio.run(sync_ids())
    args.verbose > 0 and print("Message IDs synced.")

    async def send_del_ids():
        to_del_remote = set(ids["theirs"]) - set(ids["mine"])
        args.verbose > 1 and print(f"Remote IDs to be deleted {to_del_remote}.")
        args.verbose > 0 and print("Sending message IDs to be deleted to remote...")
        to_stream.write(struct.pack("!I", len(to_del_remote)))
        transfer["write"] += 4
        to_stream.flush()
        for id in to_del_remote:
            write(id.encode("utf-8"), to_stream)

    async def del_ids():
        to_del = set(ids["mine"]) - set(ids["theirs"])
        args.verbose > 1 and print(f"Local IDs to be deleted {to_del}.")
        with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
            for id in to_del:
                dels["a"] += 1
                args.verbose > 0 and print(f"Removing {id} from DB and deleting files.")
                try:
                    msg = dbw.find(id)
                    for f in msg.filenames():
                        args.verbose > 1 and print(f"Removing {f}.")
                        dbw.remove(f)
                        Path(f).unlink()
                except LookupError:
                    # already deleted? doesn't matter
                    pass

    async def sync_dels():
        await asyncio.gather(send_del_ids(), del_ids())

    asyncio.run(sync_dels())
    return dels["a"]


def sync_deletes_remote(from_stream, to_stream):
    dels = 0
    with notmuch2.Database() as db:
        msgs = db.messages('*')
        ids = [ msg.messageid for msg in msgs ]

    to_stream.write(struct.pack("!I", len(ids)))
    transfer["write"] += 4
    to_stream.flush()
    for i in ids:
        write(i.encode("utf-8"), to_stream)

    size_data = from_stream.read(4)
    transfer["read"] += 4
    nids = struct.unpack("!I", size_data)[0]
    to_del = [ read(from_stream).decode("utf-8") for _ in range(nids) ]

    with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
        for id in to_del:
            dels += 1
            try:
                msg = dbw.find(id)
                for f in msg.filenames():
                    dbw.remove(f)
                    Path(f).unlink()
            except LookupError:
                # already deleted? doesn't matter
                pass
    return dels


def sync_remote(args):
    prefix, changes_mine, changes_theirs, tchanges = initial_sync(args, sys.stdin.buffer, sys.stdout.buffer)
    missing, fchanges, dfchanges = get_missing_files(args, changes_mine, changes_theirs, prefix)
    rchanges = sync_files(args, prefix, missing, sys.stdin.buffer, sys.stdout.buffer)
    dchanges = 0
    if args.delete:
        dchanges = sync_deletes_remote(sys.stdin.buffer, sys.stdout.buffer)
    sys.stdout.buffer.write(struct.pack("!IIIIII", tchanges, fchanges, dfchanges,
                                        rchanges["messages"], dchanges,
                                        rchanges["files"]))
    sys.stdout.buffer.flush()


def sync_local(args):
    if args.remote_cmd:
        cmd = shlex.split(args.remote_cmd)
    else:
        rargs = [(f"{args.user}@" if args.user else "") + args.remote, f"{args.path}"]
        if args.delete:
            rargs.append("--delete")
        cmd = shlex.split(args.ssh_cmd) + rargs

    args.verbose > 0 and print("Connecting to remote...")
    proc = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )

    from_remote = proc.stdout
    err_remote = proc.stderr
    to_remote = proc.stdin

    data = b''
    try:
        prefix, changes_mine, changes_theirs, tchanges = initial_sync(args, from_remote, to_remote)
        args.verbose > 1 and print(f"Local changes {changes_mine}, remote changes {changes_theirs}.")
        missing, fchanges, dfchanges  = get_missing_files(args, changes_mine, changes_theirs, prefix)
        args.verbose > 1 and print(f"Local missing files {missing}.")
        rchanges = sync_files(args, prefix, missing, from_remote, to_remote)
        dchanges = 0
        if args.delete:
            dchanges = sync_deletes_local(args, from_remote, to_remote)

        args.verbose > 0 and print("Getting change numbers from remote...")
        remote_changes = struct.unpack("!IIIIII", from_remote.read(6 * 4))
        transfer["read"] += 6 * 4
    finally:
        ready, _, exc = select([err_remote], [], [], 0)
        if ready and not exc:
            data = err_remote.read()
            # getting zero data on EOF
            if len(data) > 0:
                print(f"Remote error: {data}", file=sys.stderr)

    to_remote.close()
    from_remote.close()
    err_remote.close()
    proc.wait()

    if not args.quiet:
        print(f"local:\t{rchanges["messages"]} new messages,\t{rchanges["files"]} new files,\t{fchanges} files copied/moved,\t{dfchanges} files deleted,\t{tchanges} messages with tag changes,\t{dchanges} messages deleted")
        print(f"remote:\t{remote_changes[3]} new messages,\t{remote_changes[5]} new files,\t{remote_changes[1]} files copied/moved,\t{remote_changes[2]} files deleted,\t{remote_changes[0]} messages with tag changes,\t{remote_changes[4]} messages deleted")
        print(f"{transfer["read"]}/{transfer["write"]} bytes received from/sent to remote.")

    if len(data) > 0:
        # error output from remote
        sys.exit(1)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-r", "--remote", type=str, help="remote host to connect to")
    parser.add_argument("-u", "--user", type=str, help="SSH user to use")
    parser.add_argument("-v", "--verbose", action="count", default=0, help="increases verbosity, up to twice (ignored on remote)")
    parser.add_argument("-q", "--quiet", action="store_true", help="do not print summary")
    parser.add_argument("-s", "--ssh-cmd", type=str, default="ssh -CTaxq", help="SSH command to use")
    parser.add_argument("-m", "--mbsync", action="store_true", help="sync mbsync files (.mbsyncstate, .uidvalidity)")
    parser.add_argument("-p", "--path", type=str, default=os.path.basename(sys.argv[0]), help="path to notmuch-sync on remote server")
    parser.add_argument("-c", "--remote-cmd", type=str, help="command to run to sync; overrides --remote, --user, --ssh-cmd, --path")
    parser.add_argument("-d", "--delete", action="store_true", help="sync deleted messages (requires listing all messages in notmuch database, potentially expensive)")
    args = parser.parse_args()

    if args.remote or args.remote_cmd:
        sync_local(args)
    else:
        args.verbose = 0
        sync_remote(args)
