#!/usr/bin/env python

import argparse
import sys
import os
import struct
import subprocess
import socket
import select
import json
import shlex
import shutil
import hashlib
import asyncio
from pathlib import Path

from contextlib import contextmanager

import notmuch2

def write(data, stream):
    stream.write(struct.pack("!I", len(data)))
    stream.write(data)
    stream.flush()


def read(stream):
    size_data = stream.read(4)
    size = struct.unpack("!I", size_data)[0]
    return stream.read(size)


def get_changes(db, prefix, fname):
    """Get changes that happened since the last sync, or everything in the DB if no previous sync."""
    rev_prev = 0
    try:
        with open(fname, 'r', encoding="utf-8") as f:
            tmp = f.read().strip('\n\r').split(' ')
            revision = db.revision()
            uuid = revision.uuid.decode()
            try:
                if tmp[1] != uuid:
                    sys.exit(f"Last sync with UUID {tmp[1]}, but notmuch DB has UUID {uuid}, aborting...")
                rev_prev = int(tmp[0])
                if rev_prev > revision.rev:
                    sys.exit(f"Last sync revision {rev_prev} larger than current DB revision {revision.rev}, aborting...")
            except Exception:
                sys.exit(f"Sync state file '{fname}' corrupted, delete to sync from scratch.")
    except FileNotFoundError:
        # no previous sync or sync file broken, leave rev_prev at 0 as this will sync entire DB
        pass

    return {msg.messageid: {"tags": list(msg.tags), "files": [
        {"name": str(f).removeprefix(prefix),
         "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()} for f in msg.filenames()
        ]} for msg in db.messages(f"lastmod:{rev_prev}..")}


def sync_tags(db, changes_mine, changes_theirs):
    for id in changes_theirs:
        tags = changes_theirs[id]["tags"]
        if id in changes_mine:
            tags = list(set(tags) | set(changes_mine[id]["tags"]))
        tags = set(tags)
        try:
            msg = db.find(id)
            if tags != set(msg.tags):
                with msg.frozen():
                    msg.tags.clear()
                    for tag in sorted(list(tags)):
                        msg.tags.add(tag)
                    msg.tags.to_maildir_flags()
        except LookupError:
            # we don't have this message on our side, it will be added later
            # when syncing files
            pass


def initial_sync(sync_suffix, from_stream, to_stream):
    # only do tag sync initially to avoid locking db during lengthy file transfers
    with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
        prefix = os.path.join(str(dbw.default_path()), '')
        fname = os.path.join(prefix, ".notmuch", f"notmuch-sync-{sync_suffix}")
        # using a hash here b/c of Python's scoping rules -- need to set this in
        # the async function
        changes = {}
        changes["mine"] = get_changes(dbw, prefix, fname)

        async def send():
            write(json.dumps(changes["mine"]).encode("utf-8"), to_stream)

        async def recv():
            changes["theirs"] = json.loads(read(from_stream).decode("utf-8"))

        async def sync():
            await asyncio.gather(send(), recv())

        asyncio.run(sync())
        sync_tags(dbw, changes["mine"], changes["theirs"])
        with open(fname, 'w', encoding="utf-8") as f:
            f.write(f"{dbw.revision().rev} {dbw.revision().uuid.decode()}")

    return (prefix, changes["mine"], changes["theirs"])


def get_missing_files(changes_theirs, prefix):
    ret = {}
    with notmuch2.Database() as db:
        for id in changes_theirs:
            try:
                msg = db.find(id)
                fnames_theirs = [ f["name"] for f in changes_theirs[id]["files"] ]
                fnames_mine = [ str(f).removeprefix(prefix) for f in msg.filenames() ]
                missing_mine = [ f for f in fnames_theirs if f not in fnames_mine ]
                if len(missing_mine) > 0:
                    hashes_mine = [{"name": str(f).removeprefix(prefix),
                                    "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()}
                                    for f in msg.filenames()]
                    for f in changes_theirs[id]["files"]:
                        if f["name"] in missing_mine:
                            matches = [ x for x in hashes_mine if f["sha"] == x["sha"] ]
                            if len(matches) > 0:
                                src = os.path.join(prefix, matches[0]["name"])
                                dst = os.path.join(prefix, f["name"])
                                if matches[0] in changes_theirs[id]["files"]:
                                    shutil.copy(src, dst)
                                else:
                                    shutil.move(src, dst)
                                with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                                    dbw.add(dst)
                                    if matches[0] not in changes_theirs[id]["files"]:
                                        dbw.remove(src)
                                missing_mine.remove(f["name"])
                if len(missing_mine) > 0:
                    ret[id] = {"files": [f for f in changes_theirs[id]["files"] if f["name"] in missing_mine]}
            except LookupError:
                # don't have this message; all files missing
                ret[id] = changes_theirs[id]

    return ret


def send_file(fname, stream):
    with open(fname, "rb") as f:
        content = f.read()
        write(content, stream)


def send_files(prefix, from_stream, to_stream):
    while (line := from_stream.readline().decode("utf-8").strip()) != "SEND_END":
        cmd, _, fname = line.partition(' ')
        if cmd != "SEND":
            raise ValueError(f"Expected SEND, got '{line}'!")
        send_file(os.path.join(prefix, fname), to_stream)


def recv_file(fname, stream, sha):
    content = read(stream)
    sha_mine = hashlib.new("sha256", content).hexdigest()
    if sha_mine != sha:
        raise ValueError(f"Checksum of received file '{fname}' ({sha_mine}) does not match expected ({sha})!")
    Path(fname).parent.mkdir(parents=True, exist_ok=True)
    with open(fname, "wb") as f:
        f.write(content)


def recv_files(prefix, missing, from_stream, to_stream):
    for id in missing:
        for f in missing[id]["files"]:
            to_stream.write(f"SEND {f["name"]}\n".encode("utf-8"))
            to_stream.flush()
            dst = os.path.join(prefix, f["name"])
            recv_file(dst, from_stream, f["sha"])
            with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                msg, dup = dbw.add(dst)
                if not dup:
                    with msg.frozen():
                        msg.tags.clear()
                        for tag in missing[id]["tags"]:
                            msg.tags.add(tag)
    to_stream.write(b"SEND_END\n")
    to_stream.flush()


def sync_remote(args):
    prefix, changes_mine, changes_theirs = initial_sync(args.host, sys.stdin.buffer, sys.stdout.buffer)
    missing = get_missing_files(changes_theirs, prefix)
    send_files(prefix, sys.stdin.buffer, sys.stdout.buffer)
    recv_files(prefix, missing, sys.stdin.buffer, sys.stdout.buffer)


def sync_local(args):
    if args.remote_cmd:
        cmd = shlex.split(args.remote_cmd)
    else:
        cmd = shlex.split(args.ssh_cmd) + [(f"{args.user}@" if args.user else "") + args.remote, f"{args.path} --host {socket.getfqdn()}"]
    proc = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )

    from_remote = proc.stdout
    err_remote = proc.stderr
    to_remote = proc.stdin

    try:
        prefix, changes_mine, changes_theirs = initial_sync(args.remote, from_remote, to_remote)
        missing = get_missing_files(changes_theirs, prefix)
        recv_files(prefix, missing, from_remote, to_remote)
        send_files(prefix, from_remote, to_remote)
    finally:
        if select.select([err_remote], [], [], 0)[0]:
            print(f"Remote error: {err_remote.read()}", file=sys.stderr)

    to_remote.close()
    from_remote.close()
    err_remote.close()
    proc.wait()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-r", "--remote", type=str, help="remote host to sync with")
    parser.add_argument("-f", "--host", type=str, help="host to sync with (use with --remote-cmd)")
    parser.add_argument("-u", "--user", type=str, help="SSH user to use")
    parser.add_argument("-v", "--progress", action="store_true", help="show progress, not just summary")
    parser.add_argument("-q", "--quiet", action="store_true", help="do not show summary")
    parser.add_argument("-s", "--ssh-cmd", type=str, default="ssh -CTaxq", help="SSH command to use")
    parser.add_argument("-m", "--mbsync", action="store_true", help="sync mbsync files (.mbsyncstate, .uidvalidity)")
    parser.add_argument("-p", "--path", type=str, default=os.path.basename(sys.argv[0]), help="path to notmuch-sync on remote server")
    parser.add_argument("-c", "--remote-cmd", type=str, help="command to run to sync; overrides --remote, --user, --ssh-cmd, --path")
    parser.add_argument("-d", "--delete", action="store_true", help="sync deleted messages (requires listing all messages in notmuch database, potentially expensive)")
    args = parser.parse_args()

    if args.remote or args.remote_cmd:
        sync_local(args)
    else:
        sync_remote(args)
