#!/usr/bin/env python

import argparse
import sys
import os
import struct
import subprocess
import socket
import json
import shlex
import shutil
import hashlib
from pathlib import Path

from contextlib import contextmanager

import notmuch2

def get_changes(db, fname):
    """Get changes that happened since the last sync, or everything in the DB if no previous sync."""
    rev_prev = 0
    try:
        with open(fname, 'r', encoding="utf-8") as f:
            tmp = f.read().strip('\n\r').split(' ')
            revision = db.revision()
            uuid = revision.uuid.decode()
            try:
                if tmp[1] != uuid:
                    sys.exit(f"Last sync with UUID {tmp[1]}, but notmuch DB has UUID {uuid}, aborting...")
                rev_prev = int(tmp[0])
                if rev_prev > revision.rev:
                    sys.exit(f"Last sync revision {rev_prev} larger than current DB revision {revision.rev}, aborting...")
            except Exception:
                sys.exit(f"Sync state file '{fname}' corrupted, delete to sync from scratch.")
    except FileNotFoundError:
        # no previous sync or sync file broken, leave rev_prev at 0 as this will sync entire DB
        pass

    prefix = os.path.join(str(db.default_path()), '')
    return {msg.messageid: {"tags": list(msg.tags), "files": [
        {"name": str(f).removeprefix(prefix),
         "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()} for f in msg.filenames()
        ]} for msg in db.messages(f"lastmod:{rev_prev}..")}


@contextmanager
def initial_changes(args):
    with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as db:
        fname = os.path.join(str(db.default_path()), ".notmuch", f"notmuch-sync-{args.remote or args.host}")
        changes = get_changes(db, fname)
        yield (db, changes)
        with open(fname, 'w', encoding="utf-8") as f:
            f.write(f"{db.revision().rev} {db.revision().uuid.decode()}")


def sync_tags(db, changes_mine, changes_theirs):
    for id in changes_theirs:
        tags = changes_theirs[id]["tags"]
        if id in changes_mine:
            tags = list(set(tags) | set(changes_mine[id]["tags"]))
        tags = set(tags)
        try:
            msg = db.find(id)
            if tags != set(msg.tags):
                with msg.frozen():
                    msg.tags.clear()
                    for tag in sorted(list(tags)):
                        msg.tags.add(tag)
                    msg.tags.to_maildir_flags()
        except LookupError:
            # we don't have this message on our side, it will be added later
            # when syncing files
            pass


def get_missing_files(changes_theirs):
    ret = {}
    with notmuch2.Database() as db:
        prefix = os.path.join(str(db.default_path()), '')
        for id in changes_theirs:
            try:
                msg = db.find(id)
                fnames_theirs = [ f["name"] for f in changes_theirs[id]["files"] ]
                fnames_mine = [ str(f).removeprefix(prefix) for f in msg.filenames() ]
                missing_mine = [ f for f in fnames_theirs if f not in fnames_mine ]
                if len(missing_mine) > 0:
                    hashes_mine = [{"name": str(f).removeprefix(prefix),
                                    "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()}
                                    for f in msg.filenames()]
                    for f in changes_theirs[id]["files"]:
                        if f["name"] in missing_mine:
                            matches = [ x for x in hashes_mine if f["sha"] == x["sha"] ]
                            if len(matches) > 0:
                                src = os.path.join(prefix, matches[0]["name"])
                                dst = os.path.join(prefix, f["name"])
                                if matches[0] in changes_theirs[id]["files"]:
                                    shutil.copy(src, dst)
                                else:
                                    shutil.move(src, dst)
                                with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                                    dbw.add(dst)
                                    if matches[0] not in changes_theirs[id]["files"]:
                                        dbw.remove(src)
                                missing_mine.remove(f["name"])
                if len(missing_mine) > 0:
                    ret[id] = {"type": "add", "files": [f for f in changes_theirs[id]["files"] if f["name"] in missing_mine]}
            except LookupError:
                # don't have this message; all files missing
                ret[id] = changes_theirs[id]
                ret[id]["type"] = "new"

    return ret


def send_file(fname, stream):
    with open(fname, "r", encoding="utf-8") as f:
        lines = f.readlines()
        print(len(lines), file=stream)
        stream.flush()
        for line in lines:
            print(line, file=stream, end='')
            stream.flush()


def send_files(prefix, from_stream, to_stream):
    line = from_stream.readline().strip()
    while line != "SEND_END":
        cmd, _, fname = line.partition(' ')
        if cmd != "SEND":
            raise ValueError(f"Expected SEND, got '{line}'!")
        send_file(os.path.join(prefix, fname), to_stream)
        line = from_stream.readline().strip()


def recv_file(fname, stream, sha):
    nlines = int(stream.readline())
    contents = ''.join([ stream.readline() for i in range(0, nlines) ])
    sha_mine = hashlib.new("sha256", contents.encode()).hexdigest()
    if sha_mine != sha:
        raise ValueError(f"Checksum of received file '{fname}' ({sha_mine}) does not match expected ({sha})!")
    with open(fname, "w", encoding="utf-8") as f:
        f.write(contents)


def recv_files(prefix, missing, from_stream, to_stream):
    for id in missing:
        for f in missing[id]["files"]:
            print(f"SEND {f["name"]}", file=to_stream)
            to_stream.flush()
            dst = os.path.join(prefix, f["name"])
            recv_file(dst, from_stream, f["sha"])
            with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                dbw.add(dst)
        if missing[id]["type"] == "new":
            with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                msg = dbw.find(id)
                if missing[id]["tags"] != set(msg.tags):
                    with msg.frozen():
                        msg.tags.clear()
                        for tag in missing[id]["tags"]:
                            msg.tags.add(tag)
    print("SEND_END", file=to_stream)
    to_stream.flush()


def sync_server(args):
    changes_mine = []
    changes_theirs = []
    prefix = ''
    # only do tag sync initially to avoid locking db during lengthy file
    # transfers
    with initial_changes(args) as (dbw, tmp):
        prefix = os.path.join(str(dbw.default_path()), '')
        changes_mine = tmp
        print(json.dumps(changes_mine))
        sys.stdout.flush()
        changes_theirs = json.loads(sys.stdin.readline())
        sync_tags(dbw, changes_mine, changes_theirs)

    missing = get_missing_files(changes_theirs)
    send_files(prefix, sys.stdin, sys.stdout)
    recv_files(prefix, missing, sys.stdin, sys.stdout)


def sync_client(args):
    if args.remote_cmd:
        cmd = shlex.split(args.remote_cmd)
    else:
        cmd = shlex.split(args.ssh_cmd) + [(f"{args.user}@" if args.user else "") + args.remote, f"{args.path} --host {socket.getfqdn()}"]
    proc = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        bufsize=1
    )

    from_remote = proc.stdout
    err_remote = proc.stderr
    to_remote = proc.stdin

    changes_mine = []
    changes_theirs = []
    prefix = ''
    # only do tag sync initially to avoid locking db during lengthy file
    # transfers
    with initial_changes(args) as (dbw, tmp):
        prefix = os.path.join(str(dbw.default_path()), '')
        changes_mine = tmp
        changes_theirs = json.loads(from_remote.readline())
        print(json.dumps(changes_mine), file=to_remote)
        to_remote.flush()
        sync_tags(dbw, changes_mine, changes_theirs)

    missing = get_missing_files(changes_theirs)
    recv_files(prefix, missing, from_remote, to_remote)
    send_files(prefix, from_remote, to_remote)

    err = err_remote.read()
    if err:
        print(f"Remote error: {err}", file=sys.stderr)

    to_remote.close()
    from_remote.close()
    err_remote.close()
    proc.wait()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-r", "--remote", type=str, help="remote host to sync with")
    parser.add_argument("-f", "--host", type=str, help="host to sync with (use with --remote-cmd)")
    parser.add_argument("-u", "--user", type=str, help="SSH user to use")
    parser.add_argument("-v", "--progress", action="store_true", help="show progress, not just summary")
    parser.add_argument("-s", "--ssh-cmd", type=str, default="ssh -CTaxq", help="SSH command to use")
    parser.add_argument("-m", "--mbsync", action="store_true", help="sync mbsync files (.mbsyncstate, .uidvalidity)")
    parser.add_argument("-p", "--path", type=str, default=os.path.basename(sys.argv[0]), help="path to notmuch-sync on remote server")
    parser.add_argument("-c", "--remote-cmd", type=str, help="command to run to sync; overrides --remote, --user, --ssh-cmd, --path")
    parser.add_argument("-d", "--delete", action="store_true", help="sync deleted messages (requires listing all messages in notmuch database, potentially expensive)")
    args = parser.parse_args()

    if args.remote or args.remote_cmd:
        sync_client(args)
    else:
        sync_server(args)
