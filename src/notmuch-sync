#!/usr/bin/env python

import argparse
import sys
import os
import struct
import subprocess
import socket
import select
import json
import shlex
import shutil
import hashlib
import asyncio
from pathlib import Path

import notmuch2

def write(data, stream):
    stream.write(struct.pack("!I", len(data)))
    stream.write(data)
    stream.flush()


def read(stream):
    size_data = stream.read(4)
    size = struct.unpack("!I", size_data)[0]
    return stream.read(size)


def get_changes(db, revision, prefix, fname):
    """Get changes that happened since the last sync, or everything in the DB if no previous sync."""
    rev_prev = -1
    try:
        with open(fname, 'r', encoding="utf-8") as f:
            tmp = f.read().strip('\n\r').split(' ')
            uuid = revision.uuid.decode()
            try:
                if tmp[1] != uuid:
                    sys.exit(f"Last sync with UUID {tmp[1]}, but notmuch DB has UUID {uuid}, aborting...")
                rev_prev = int(tmp[0])
                if rev_prev > revision.rev:
                    sys.exit(f"Last sync revision {rev_prev} larger than current DB revision {revision.rev}, aborting...")
            except Exception:
                sys.exit(f"Sync state file '{fname}' corrupted, delete to sync from scratch.")
    except FileNotFoundError:
        # no previous sync or sync file broken, leave rev_prev at 0 as this will sync entire DB
        pass

    return {msg.messageid: {"tags": list(msg.tags), "files": [
        {"name": str(f).removeprefix(prefix),
         "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()} for f in msg.filenames()
        ]} for msg in db.messages(f"lastmod:{rev_prev + 1}..")}


def sync_tags(args, db, changes_mine, changes_theirs):
    changes = 0
    for id in changes_theirs:
        tags = changes_theirs[id]["tags"]
        if id in changes_mine:
            tags = list(set(tags) | set(changes_mine[id]["tags"]))
        tags = set(tags)
        try:
            msg = db.find(id)
            if tags != set(msg.tags):
                args.verbose > 0 and print(f"Setting tags {sorted(list(tags))} for {id}.")
                with msg.frozen():
                    changes += 1
                    msg.tags.clear()
                    for tag in sorted(list(tags)):
                        msg.tags.add(tag)
                    msg.tags.to_maildir_flags()
        except LookupError:
            # we don't have this message on our side, it will be added later
            # when syncing files
            pass

    return changes


def initial_sync(args, from_stream, to_stream):
    # only do tag sync initially to avoid locking db during lengthy file transfers
    with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
        prefix = os.path.join(str(dbw.default_path()), '')
        revision = dbw.revision()
        # using a hash here b/c of Python's scoping rules -- need to set this in
        # the async function
        uuids = {}
        uuids["mine"] = revision.uuid.decode()

        async def send_uuid():
            args.verbose > 0 and print("Sending UUID...")
            to_stream.write(uuids["mine"].encode("utf-8"))
            to_stream.flush()

        async def recv_uuid():
            args.verbose > 0 and print("Receiving UUID...")
            uuids["theirs"] = from_stream.read(36).decode("utf-8")

        async def sync_uuids():
            await asyncio.gather(send_uuid(), recv_uuid())

        asyncio.run(sync_uuids())
        args.verbose > 0 and print("UUIDs synced.")
        fname = os.path.join(prefix, ".notmuch", f"notmuch-sync-{uuids["theirs"]}")

        changes = {}
        args.verbose > 0 and print("Computing local changes...")
        changes["mine"] = get_changes(dbw, revision, prefix, fname)

        async def send():
            args.verbose > 0 and print("Sending local changes...")
            write(json.dumps(changes["mine"]).encode("utf-8"), to_stream)

        async def recv():
            args.verbose > 0 and print("Receiving remote changes...")
            changes["theirs"] = json.loads(read(from_stream).decode("utf-8"))

        async def sync():
            await asyncio.gather(send(), recv())

        asyncio.run(sync())
        args.verbose > 0 and print("Changes synced.")
        tchanges = sync_tags(args, dbw, changes["mine"], changes["theirs"])

        # record last sync here -- this means that later changes (adding files,
        # adding messages, deleting) will show up during the next sync, but we
        # check whether there are any actual changes, so they shouldn't result
        # in a cascading torrent
        # if we don't record the last sync here, we might miss external changes
        # during the next stages, as the DB is no longer locked
        with open(fname, 'w', encoding="utf-8") as f:
            revision = dbw.revision()
            args.verbose > 0 and print(f"Writing last sync revision {revision.rev}.")
            f.write(f"{revision.rev} {revision.uuid.decode()}")

    return (prefix, changes["mine"], changes["theirs"], tchanges)


def get_missing_files(args, changes_mine, changes_theirs, prefix):
    ret = {}
    changes = 0
    with notmuch2.Database() as db:
        for id in changes_theirs:
            try:
                msg = db.find(id)
                fnames_theirs = [ f["name"] for f in changes_theirs[id]["files"] ]
                fnames_mine = [ str(f).removeprefix(prefix) for f in msg.filenames() ]
                missing_mine = [ f for f in fnames_theirs if f not in fnames_mine ]
                if len(missing_mine) > 0:
                    hashes_mine = [{"name": str(f).removeprefix(prefix),
                                    "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()}
                                    for f in msg.filenames()]
                    for f in changes_theirs[id]["files"]:
                        if f["name"] in missing_mine:
                            # check if it has been moved/copied
                            matches = [ x for x in hashes_mine if f["sha"] == x["sha"] ]
                            if len(matches) > 0:
                                changes += 1
                                src = os.path.join(prefix, matches[0]["name"])
                                dst = os.path.join(prefix, f["name"])
                                # if there's a local change for this ID, copy
                                # this is to prevent inconsistencies when
                                # changes happen on both sides
                                if matches[0] in changes_theirs[id]["files"] or id in changes_mine:
                                    args.verbose > 0 and print(f"Copying {src} to {dst}.")
                                    shutil.copy(src, dst)
                                else:
                                    args.verbose > 0 and print(f"Moving {src} to {dst}.")
                                    shutil.move(src, dst)
                                with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                                    dbw.add(dst)
                                    # see above comment for local changes check
                                    if matches[0] not in changes_theirs[id]["files"] and id not in changes_mine:
                                        args.verbose > 0 and print(f"Removing {src} from DB.")
                                        dbw.remove(src)
                                missing_mine.remove(f["name"])
                # check which ones are still missing
                if len(missing_mine) > 0:
                    ret[id] = {"files": [f for f in changes_theirs[id]["files"] if f["name"] in missing_mine]}
            except LookupError:
                # don't have this message; all files missing
                ret[id] = changes_theirs[id]
    return (ret, changes)


def send_file(fname, stream):
    with open(fname, "rb") as f:
        write(f.read(), stream)


def recv_file(fname, stream, sha):
    content = read(stream)
    sha_mine = hashlib.new("sha256", content).hexdigest()
    if sha_mine != sha:
        raise ValueError(f"Checksum of received file '{fname}' ({sha_mine}) does not match expected ({sha})!")
    Path(fname).parent.mkdir(parents=True, exist_ok=True)
    with open(fname, "wb") as f:
        f.write(content)


def sync_files(args, prefix, missing, from_stream, to_stream):
    files = {}
    files["mine"] = [ f | {"id": id} for id in missing for f in missing[id]["files"] ]
    changes = {"files": len(files["mine"]), "messages": 0}

    async def send_fnames():
        args.verbose > 0 and print("Sending file names missing on local...")
        to_stream.write(struct.pack("!I", len(files["mine"])))
        to_stream.flush()
        for f in files["mine"]:
            write(f["name"].encode("utf-8"), to_stream)

    async def recv_fnames():
        args.verbose > 0 and print("Receving file names missing on remote...")
        size_data = from_stream.read(4)
        nfiles = struct.unpack("!I", size_data)[0]
        files["theirs"] = [ read(from_stream).decode("utf-8") for _ in range(nfiles) ]

    async def sync_fnames():
        await asyncio.gather(send_fnames(), recv_fnames())

    asyncio.run(sync_fnames())
    args.verbose > 0 and print("Missing file names synced.")

    async def send_files():
        for idx, fname in enumerate(files["theirs"]):
            args.verbose > 0 and print(f"{idx + 1}/{len(files["theirs"])} Sending {fname}...")
            send_file(os.path.join(prefix, fname), to_stream)
    
    async def recv_files():
        for idx, f in enumerate(files["mine"]):
            args.verbose > 0 and print(f"{idx + 1}/{len(files["mine"])} Receiving {f["name"]}...")
            dst = os.path.join(prefix, f["name"])
            recv_file(dst, from_stream, f["sha"])
            with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                args.verbose > 0 and print(f"Adding {dst} to DB.")
                msg, dup = dbw.add(dst)
                if not dup:
                    changes["messages"] += 1
                    with msg.frozen():
                        args.verbose > 0 and print(f"Setting tags {sorted(missing[f["id"]]["tags"])} for {msg.messageid}.")
                        msg.tags.clear()
                        for tag in missing[f["id"]]["tags"]:
                            msg.tags.add(tag)

    async def sync():
        await asyncio.gather(send_files(), recv_files())

    asyncio.run(sync())
    args.verbose > 0 and print("Missing files synced.")

    return changes


def sync_remote(args):
    prefix, changes_mine, changes_theirs, tchanges = initial_sync(args, sys.stdin.buffer, sys.stdout.buffer)
    missing, fchanges = get_missing_files(args, changes_mine, changes_theirs, prefix)
    rchanges = sync_files(args, prefix, missing, sys.stdin.buffer, sys.stdout.buffer)
    sys.stdout.buffer.write(struct.pack("!IIII", tchanges, fchanges,
                                        rchanges["messages"],
                                        rchanges["files"]))
    sys.stdout.buffer.flush()


def sync_local(args):
    if args.remote_cmd:
        cmd = shlex.split(args.remote_cmd)
    else:
        cmd = shlex.split(args.ssh_cmd) + [(f"{args.user}@" if args.user else "") + args.remote, f"{args.path}"]

    args.verbose > 0 and print("Connecting to remote...")
    proc = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )

    from_remote = proc.stdout
    err_remote = proc.stderr
    to_remote = proc.stdin

    try:
        prefix, changes_mine, changes_theirs, tchanges = initial_sync(args, from_remote, to_remote)
        args.verbose > 1 and print(f"Local changes {changes_mine}, remote changes {changes_theirs}.")
        missing, fchanges = get_missing_files(args, changes_mine, changes_theirs, prefix)
        args.verbose > 1 and print(f"Local missing files {missing}.")
        rchanges = sync_files(args, prefix, missing, from_remote, to_remote)

        args.verbose > 0 and print("Getting change numbers from remote...")
        remote_changes = struct.unpack("!IIII", from_remote.read(4 * 4))
    finally:
        if select.select([err_remote], [], [], 0)[0]:
            print(f"Remote error: {err_remote.read()}", file=sys.stderr)

    to_remote.close()
    from_remote.close()
    err_remote.close()
    proc.wait()

    if not args.quiet:
        print(f"local:\t{rchanges["messages"]} new messages,\t{rchanges["files"]} new files,\t{fchanges} files copied/moved,\t{tchanges} messages with tag changes")
        print(f"remote:\t{remote_changes[2]} new messages,\t{remote_changes[3]} new files,\t{remote_changes[1]} files copied/moved,\t{remote_changes[0]} messages with tag changes")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-r", "--remote", type=str, help="remote host to connect to")
    parser.add_argument("-u", "--user", type=str, help="SSH user to use")
    parser.add_argument("-v", "--verbose", action="count", default=0, help="increases verbosity, up to twice (ignored on remote)")
    parser.add_argument("-q", "--quiet", action="store_true", help="do not print summary")
    parser.add_argument("-s", "--ssh-cmd", type=str, default="ssh -CTaxq", help="SSH command to use")
    parser.add_argument("-m", "--mbsync", action="store_true", help="sync mbsync files (.mbsyncstate, .uidvalidity)")
    parser.add_argument("-p", "--path", type=str, default=os.path.basename(sys.argv[0]), help="path to notmuch-sync on remote server")
    parser.add_argument("-c", "--remote-cmd", type=str, help="command to run to sync; overrides --remote, --user, --ssh-cmd, --path")
    parser.add_argument("-d", "--delete", action="store_true", help="sync deleted messages (requires listing all messages in notmuch database, potentially expensive)")
    args = parser.parse_args()

    if args.remote or args.remote_cmd:
        sync_local(args)
    else:
        args.verbose = 0
        sync_remote(args)
