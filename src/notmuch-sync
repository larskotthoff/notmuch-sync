#!/usr/bin/env python

import argparse
import sys
import os
import struct
import subprocess
import socket
import select
import json
import shlex
import shutil
import hashlib
import asyncio
from pathlib import Path

import notmuch2

def write(data, stream):
    stream.write(struct.pack("!I", len(data)))
    stream.write(data)
    stream.flush()


def read(stream):
    size_data = stream.read(4)
    size = struct.unpack("!I", size_data)[0]
    return stream.read(size)


def get_changes(db, revision, prefix, fname):
    """Get changes that happened since the last sync, or everything in the DB if no previous sync."""
    rev_prev = 0
    try:
        with open(fname, 'r', encoding="utf-8") as f:
            tmp = f.read().strip('\n\r').split(' ')
            uuid = revision.uuid.decode()
            try:
                if tmp[1] != uuid:
                    sys.exit(f"Last sync with UUID {tmp[1]}, but notmuch DB has UUID {uuid}, aborting...")
                rev_prev = int(tmp[0])
                if rev_prev > revision.rev:
                    sys.exit(f"Last sync revision {rev_prev} larger than current DB revision {revision.rev}, aborting...")
            except Exception:
                sys.exit(f"Sync state file '{fname}' corrupted, delete to sync from scratch.")
    except FileNotFoundError:
        # no previous sync or sync file broken, leave rev_prev at 0 as this will sync entire DB
        pass

    return {msg.messageid: {"tags": list(msg.tags), "files": [
        {"name": str(f).removeprefix(prefix),
         "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()} for f in msg.filenames()
        ]} for msg in db.messages(f"lastmod:{rev_prev}..")}


def sync_tags(db, changes_mine, changes_theirs):
    for id in changes_theirs:
        tags = changes_theirs[id]["tags"]
        if id in changes_mine:
            tags = list(set(tags) | set(changes_mine[id]["tags"]))
        tags = set(tags)
        try:
            msg = db.find(id)
            if tags != set(msg.tags):
                with msg.frozen():
                    msg.tags.clear()
                    for tag in sorted(list(tags)):
                        msg.tags.add(tag)
                    msg.tags.to_maildir_flags()
        except LookupError:
            # we don't have this message on our side, it will be added later
            # when syncing files
            pass


def initial_sync(from_stream, to_stream):
    # only do tag sync initially to avoid locking db during lengthy file transfers
    with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
        prefix = os.path.join(str(dbw.default_path()), '')
        revision = dbw.revision()
        # using a hash here b/c of Python's scoping rules -- need to set this in
        # the async function
        uuids = {}
        uuids["mine"] = revision.uuid.decode()

        async def send_uuid():
            to_stream.write(uuids["mine"].encode("utf-8"))
            to_stream.flush()

        async def recv_uuid():
            uuids["theirs"] = from_stream.read(36).decode("utf-8")

        async def sync_uuids():
            await asyncio.gather(send_uuid(), recv_uuid())

        asyncio.run(sync_uuids())
        fname = os.path.join(prefix, ".notmuch", f"notmuch-sync-{uuids["theirs"]}")

        changes = {}
        changes["mine"] = get_changes(dbw, revision, prefix, fname)

        async def send():
            write(json.dumps(changes["mine"]).encode("utf-8"), to_stream)

        async def recv():
            changes["theirs"] = json.loads(read(from_stream).decode("utf-8"))

        async def sync():
            await asyncio.gather(send(), recv())

        asyncio.run(sync())
        sync_tags(dbw, changes["mine"], changes["theirs"])

        # record last sync here -- this means that later changes (adding files,
        # adding messages, deleting) will show up during the next sync, but we
        # check whether there are any actual changes, so they shouldn't result
        # in a cascading torrent
        # if we don't record the last sync here, we might miss external changes
        # during the next stages, as the DB is no longer locked
        with open(fname, 'w', encoding="utf-8") as f:
            revision = dbw.revision()
            f.write(f"{revision.rev} {revision.uuid.decode()}")

    return (prefix, changes["mine"], changes["theirs"])


def get_missing_files(changes_theirs, prefix):
    ret = {}
    with notmuch2.Database() as db:
        for id in changes_theirs:
            try:
                msg = db.find(id)
                fnames_theirs = [ f["name"] for f in changes_theirs[id]["files"] ]
                fnames_mine = [ str(f).removeprefix(prefix) for f in msg.filenames() ]
                missing_mine = [ f for f in fnames_theirs if f not in fnames_mine ]
                if len(missing_mine) > 0:
                    hashes_mine = [{"name": str(f).removeprefix(prefix),
                                    "sha": hashlib.new("sha256", Path(f).read_bytes()).hexdigest()}
                                    for f in msg.filenames()]
                    for f in changes_theirs[id]["files"]:
                        if f["name"] in missing_mine:
                            matches = [ x for x in hashes_mine if f["sha"] == x["sha"] ]
                            if len(matches) > 0:
                                src = os.path.join(prefix, matches[0]["name"])
                                dst = os.path.join(prefix, f["name"])
                                if matches[0] in changes_theirs[id]["files"]:
                                    shutil.copy(src, dst)
                                else:
                                    shutil.move(src, dst)
                                with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                                    dbw.add(dst)
                                    if matches[0] not in changes_theirs[id]["files"]:
                                        dbw.remove(src)
                                missing_mine.remove(f["name"])
                if len(missing_mine) > 0:
                    ret[id] = {"files": [f for f in changes_theirs[id]["files"] if f["name"] in missing_mine]}
            except LookupError:
                # don't have this message; all files missing
                ret[id] = changes_theirs[id]
    return ret


def send_file(fname, stream):
    with open(fname, "rb") as f:
        write(f.read(), stream)


def recv_file(fname, stream, sha):
    content = read(stream)
    sha_mine = hashlib.new("sha256", content).hexdigest()
    if sha_mine != sha:
        raise ValueError(f"Checksum of received file '{fname}' ({sha_mine}) does not match expected ({sha})!")
    Path(fname).parent.mkdir(parents=True, exist_ok=True)
    with open(fname, "wb") as f:
        f.write(content)


def sync_files(prefix, missing, from_stream, to_stream):
    files = {}
    files["mine"] = [ f | {"id": id} for id in missing for f in missing[id]["files"] ]

    async def send_fnames():
        to_stream.write(struct.pack("!I", len(files["mine"])))
        to_stream.flush()
        for f in files["mine"]:
            write(f["name"].encode("utf-8"), to_stream)

    async def recv_fnames():
        size_data = from_stream.read(4)
        nfiles = struct.unpack("!I", size_data)[0]
        files["theirs"] = [ read(from_stream).decode("utf-8") for _ in range(nfiles) ]

    async def sync_fnames():
        await asyncio.gather(send_fnames(), recv_fnames())

    asyncio.run(sync_fnames())

    async def send_files():
        for fname in files["theirs"]:
            send_file(os.path.join(prefix, fname), to_stream)
    
    async def recv_files():
        for f in files["mine"]:
            dst = os.path.join(prefix, f["name"])
            recv_file(dst, from_stream, f["sha"])
            with notmuch2.Database(mode=notmuch2.Database.MODE.READ_WRITE) as dbw:
                msg, dup = dbw.add(dst)
                if not dup:
                    with msg.frozen():
                        msg.tags.clear()
                        for tag in missing[f["id"]]["tags"]:
                            msg.tags.add(tag)

    async def sync():
        await asyncio.gather(send_files(), recv_files())

    asyncio.run(sync())


def sync_remote(args):
    prefix, changes_mine, changes_theirs = initial_sync(sys.stdin.buffer, sys.stdout.buffer)
    missing = get_missing_files(changes_theirs, prefix)
    sync_files(prefix, missing, sys.stdin.buffer, sys.stdout.buffer)


def sync_local(args):
    if args.remote_cmd:
        cmd = shlex.split(args.remote_cmd)
    else:
        cmd = shlex.split(args.ssh_cmd) + [(f"{args.user}@" if args.user else "") + args.remote, f"{args.path}"]
    proc = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )

    from_remote = proc.stdout
    err_remote = proc.stderr
    to_remote = proc.stdin

    try:
        prefix, changes_mine, changes_theirs = initial_sync(from_remote, to_remote)
        missing = get_missing_files(changes_theirs, prefix)
        sync_files(prefix, missing, from_remote, to_remote)
    finally:
        if select.select([err_remote], [], [], 0)[0]:
            print(f"Remote error: {err_remote.read()}", file=sys.stderr)

    to_remote.close()
    from_remote.close()
    err_remote.close()
    proc.wait()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-r", "--remote", type=str, help="remote host to connect to")
    parser.add_argument("-u", "--user", type=str, help="SSH user to use")
    parser.add_argument("-v", "--progress", action="store_true", help="show progress, not just summary")
    parser.add_argument("-q", "--quiet", action="store_true", help="do not show summary")
    parser.add_argument("-s", "--ssh-cmd", type=str, default="ssh -CTaxq", help="SSH command to use")
    parser.add_argument("-m", "--mbsync", action="store_true", help="sync mbsync files (.mbsyncstate, .uidvalidity)")
    parser.add_argument("-p", "--path", type=str, default=os.path.basename(sys.argv[0]), help="path to notmuch-sync on remote server")
    parser.add_argument("-c", "--remote-cmd", type=str, help="command to run to sync; overrides --remote, --user, --ssh-cmd, --path")
    parser.add_argument("-d", "--delete", action="store_true", help="sync deleted messages (requires listing all messages in notmuch database, potentially expensive)")
    args = parser.parse_args()

    if args.remote or args.remote_cmd:
        sync_local(args)
    else:
        sync_remote(args)
